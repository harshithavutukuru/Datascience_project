{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Mount drive"
      ],
      "metadata": {
        "id": "oBO_CNiGPI56"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EBQ7Znh7rRq-"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9UkWLJQ_HFNs"
      },
      "outputs": [],
      "source": [
        "!pip install kaggle -Uqq\n",
        "!mkdir /root/.kaggle\n",
        "!mkdir model_checkpoints\n",
        "!cp /content/drive/MyDrive/kaggle.json  /root/.kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bh3YWdg-J94F"
      },
      "outputs": [],
      "source": [
        "!cp /content/drive/MyDrive/kaggle.json  /root/.kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "clXfYbVtrfT8"
      },
      "outputs": [],
      "source": [
        "\n",
        "!pip install wandb -Uqq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "am2aPKUAhA-1"
      },
      "outputs": [],
      "source": [
        "!kaggle datasets download -d preetviradiya/brian-tumor-dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I1UGgo8BIiR-"
      },
      "outputs": [],
      "source": [
        "!mkdir data\n",
        "!unzip -d data -q /content/brian-tumor-dataset.zip\n",
        "!rm -rf /content/brian-tumor-dataset.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C0wG-0_ALYZs"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ia48B4sYLZzN"
      },
      "outputs": [],
      "source": [
        "metadata = pd.read_csv(\"/content/data/metadata.csv\")\n",
        "metadata_rgb = pd.read_csv(\"/content/data/metadata_rgb_only.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lHL3lqodLsch"
      },
      "outputs": [],
      "source": [
        "metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CS_J1UA1L1cK"
      },
      "outputs": [],
      "source": [
        "metadata_rgb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f51ggHXuqFut"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "import wandb\n",
        "from wandb.integration.keras import WandbCallback\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U47x2jSHqUT1"
      },
      "outputs": [],
      "source": [
        "tf.keras.utils.set_random_seed(42)\n",
        "tf.config.experimental.enable_op_determinism()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yeaivOM5q4LN"
      },
      "outputs": [],
      "source": [
        "path = Path('/content/data/Brain Tumor Data Set/Brain Tumor Data Set')\n",
        "batch_size = 32\n",
        "img_height = 224\n",
        "img_width = 224\n",
        "\n",
        "train_ds, val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  path,\n",
        "  validation_split=0.2,\n",
        "  subset=\"both\",\n",
        "  seed=42,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_HcX7xgdtJl_"
      },
      "outputs": [],
      "source": [
        "class_names = train_ds.class_names\n",
        "print(class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DZbkSO6rt0gR"
      },
      "outputs": [],
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "resnet_base = tf.keras.applications.ResNet50(\n",
        "    include_top=False,\n",
        "    weights=\"imagenet\",\n",
        "    input_shape=(224,224,3),\n",
        "    pooling='avg',\n",
        ")\n",
        "rescaling = layers.Rescaling(1.0 / 255)\n",
        "resize = layers.Resizing(img_height, img_width)\n",
        "\n",
        "model = Sequential()\n",
        "#rescale and resize the image\n",
        "model.add(resize)\n",
        "model.add(rescaling)\n",
        "\n",
        "model.add(resnet_base)\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "#freeze the base resnet_base from model\n",
        "resnet_base.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "arSYSWSRymDV"
      },
      "outputs": [],
      "source": [
        "batch = next(iter(train_ds))\n",
        "outputs = model(batch[0])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LEwghRCUuebq"
      },
      "outputs": [],
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "loss = tf.keras.losses.BinaryCrossentropy()\n",
        "roc_auc = tf.keras.metrics.AUC(curve='ROC', name='roc_auc')\n",
        "accuracy = tf.keras.metrics.BinaryAccuracy(name='accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xsVnKY_zvCWo"
      },
      "outputs": [],
      "source": [
        "# define callbacks\n",
        "decay_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor=\"val_loss\",\n",
        "    factor=0.1,\n",
        "    patience=3,\n",
        "    verbose=1,\n",
        "    mode=\"auto\",\n",
        "    min_delta=0.0001,\n",
        "    cooldown=0,\n",
        "    min_lr=0,\n",
        ")\n",
        "checkpoint_filepath = \"/content/model_checkpoints/models_resnet_50/model_{epoch:02d}_val_roc_auc_{val_roc_auc:.4f}_val_loss_{val_loss:.4f}_val_accuracy_{val_accuracy:.4f}.weights.h5\"\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    monitor=\"val_loss\",\n",
        "    verbose=0,\n",
        "    save_best_only=True,\n",
        "    save_weights_only=True,\n",
        "    mode=\"auto\",\n",
        "    save_freq=\"epoch\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-LCzkqJawyfV"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=optimizer, loss=loss, metrics=[roc_auc, accuracy])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d8VIEjT21V-J"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "WANDB_API_KEY = userdata.get('wandb')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UaCj2Kmozga0"
      },
      "outputs": [],
      "source": [
        "wandb.login(key=WANDB_API_KEY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwCJBBhJNjcW"
      },
      "outputs": [],
      "source": [
        "!wandb login --relogin\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "addKVCD9RKvc"
      },
      "outputs": [],
      "source": [
        "import wandb\n",
        "\n",
        "# Replace 'your-api-key' with your actual W&B API key\n",
        "wandb.login(key='14490665281cfce57ebb93f7fbc543f719e0c014')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GOyz8mky3d6o"
      },
      "outputs": [],
      "source": [
        "run = wandb.init(project=\"cortex\", entity=\"shivanikotian18\", job_type=\"finetune\", group='resnet',tags=['ResNet50'])\n",
        "assert run is wandb.run, \"Something went wrong\"\n",
        "#train and validate the model\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=40,\n",
        "    callbacks=[checkpoint, WandbCallback(save_weights_only=False)],\n",
        ")\n",
        "run.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "djEBie_0IRqK"
      },
      "outputs": [],
      "source": [
        "tf.keras.backend.clear_session()\n",
        "VGG_model = Sequential()\n",
        "\n",
        "pretrained_model= keras.applications.VGG19(include_top=False,\n",
        "                   input_shape=(224,224,3),\n",
        "                   pooling='avg',\n",
        "                   weights='imagenet')\n",
        "\n",
        "rescaling = layers.Rescaling(1.0 / 255)\n",
        "resize = layers.Resizing(img_height, img_width)\n",
        "\n",
        "#rescale and resize the image\n",
        "VGG_model.add(resize)\n",
        "VGG_model.add(rescaling)\n",
        "VGG_model.add(pretrained_model)\n",
        "\n",
        "\n",
        "VGG_model.add(Dense(1, activation='sigmoid'))\n",
        "pretrained_model.trainable=False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B30BRZQzZ1j3"
      },
      "outputs": [],
      "source": [
        "batch = next(iter(train_ds))\n",
        "outputs = VGG_model(batch[0])\n",
        "VGG_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "phYeKVB-Z44z"
      },
      "outputs": [],
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "loss = tf.keras.losses.BinaryCrossentropy()\n",
        "roc_auc = tf.keras.metrics.AUC(curve='ROC', name='roc_auc')\n",
        "accuracy = tf.keras.metrics.BinaryAccuracy(name='accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qezyzZJhIbu3"
      },
      "outputs": [],
      "source": [
        "VGG_model.compile(optimizer=optimizer, loss=loss, metrics=[roc_auc, accuracy])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hDX_TG9_WNl4"
      },
      "outputs": [],
      "source": [
        "# define callbacks\n",
        "decay_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor=\"val_loss\",\n",
        "    factor=0.1,\n",
        "    patience=3,\n",
        "    verbose=1,\n",
        "    mode=\"auto\",\n",
        "    min_delta=0.0001,\n",
        "    cooldown=0,\n",
        "    min_lr=0,\n",
        ")\n",
        "\n",
        "checkpoint_filepath_vgg = \"/content/model_checkpoints/models_vgg_19/model_{epoch:02d}_val_roc_auc_{val_roc_auc:.4f}_val_loss_{val_loss:.4f}_val_accuracy_{val_accuracy:.4f}.keras\"\n",
        "checkpoint_vgg = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath_vgg,\n",
        "    monitor=\"val_loss\",\n",
        "    verbose=0,\n",
        "    save_best_only=True,\n",
        "    save_weights_only=True,\n",
        "    mode=\"auto\",\n",
        "    save_freq=\"epoch\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bLEM2pFWIs9y"
      },
      "outputs": [],
      "source": [
        "run_vgg = wandb.init(project=\"combined\", entity=\"shivanikotian18\", job_type=\"finetune\", group='vgg',tags=['VGG19'])\n",
        "#train and validate the model\n",
        "history = VGG_model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=40,\n",
        "    callbacks=[checkpoint_vgg, WandbCallback(save_weights_only=False)],\n",
        ")\n",
        "run_vgg.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T8DUn5aSC2Yj"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fb5o7wiAgaAq"
      },
      "outputs": [],
      "source": [
        "# Clear any previous model session to start fresh\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# Initialize a Sequential model\n",
        "custom_model = Sequential()\n",
        "\n",
        "# Add a 2D convolution layer with 16 filters, a 3x3 kernel, and 'relu' activation function\n",
        "custom_model.add(Conv2D(16, (3, 3), activation='relu', padding = \"same\", input_shape=(224, 224, 3)))\n",
        "\n",
        "# Add a max pooling layer to reduce the spatial dimensions of the output volume\n",
        "custom_model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "# Add another convolution and max pooling layer\n",
        "custom_model.add(Conv2D(8, (3, 3), activation='relu', padding = \"same\"))\n",
        "custom_model.add(MaxPool2D((2,2)))\n",
        "\n",
        "# Flatten the tensor output from the previous layer to create a single long feature vector\n",
        "custom_model.add(Flatten())\n",
        "\n",
        "# Add a dense layer with 8 neurons and 'relu' activation function\n",
        "custom_model.add(Dense(8, activation='relu'))\n",
        "\n",
        "# Add batch normalization layer to normalize the activations of the previous layer\n",
        "custom_model.add(BatchNormalization())\n",
        "\n",
        "# Add a dropout layer to prevent overfitting\n",
        "custom_model.add(Dropout(0.3))\n",
        "\n",
        "# Add the output layer with a single neuron (for binary classification) and 'sigmoid' activation function\n",
        "custom_model.add(Dense(1, activation='sigmoid'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xHq-IRpJAKMX"
      },
      "outputs": [],
      "source": [
        "batch = next(iter(train_ds))\n",
        "outputs = custom_model(batch[0])\n",
        "custom_model.summary()\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "loss = tf.keras.losses.BinaryCrossentropy()\n",
        "roc_auc = tf.keras.metrics.AUC(curve='ROC', name='roc_auc')\n",
        "accuracy = tf.keras.metrics.BinaryAccuracy(name='accuracy')\n",
        "\n",
        "custom_model.compile(optimizer=optimizer, loss=loss, metrics=[roc_auc, accuracy])\n",
        "\n",
        "# define callbacks\n",
        "decay_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor=\"val_loss\",\n",
        "    factor=0.1,\n",
        "    patience=3,\n",
        "    verbose=1,\n",
        "    mode=\"auto\",\n",
        "    min_delta=0.0001,\n",
        "    cooldown=0,\n",
        "    min_lr=0,\n",
        ")\n",
        "\n",
        "checkpoint_filepath_custom = \"/content/model_checkpoints/models_custom/model_{epoch:02d}_val_roc_auc_{val_roc_auc:.4f}_val_loss_{val_loss:.4f}_val_accuracy_{val_accuracy:.4f}.keras\"\n",
        "checkpoint_custom = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath_custom,\n",
        "    monitor=\"val_loss\",\n",
        "    verbose=0,\n",
        "    save_best_only=True,\n",
        "    save_weights_only=True,\n",
        "    mode=\"auto\",\n",
        "    save_freq=\"epoch\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_9z2_fq0AcV5"
      },
      "outputs": [],
      "source": [
        "run_custom = wandb.init(project=\"cortex\", entity=\"shivanikotian18\", job_type=\"finetune\", group='custom',tags=['Custom_model'])\n",
        "#train and validate the model\n",
        "history = custom_model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=40,\n",
        "    callbacks=[checkpoint_custom, WandbCallback(save_weights_only=False)],\n",
        ")\n",
        "run_custom.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0H7GWpcDKVr-"
      },
      "outputs": [],
      "source": [
        "pip install wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uMRLhhXnTo7p"
      },
      "outputs": [],
      "source": [
        "import wandb\n",
        "from tensorflow.keras.models import load_model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8JQBGPecMTV1"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# The artifact directory will contain the saved model file\n",
        "loaded_model = load_model(f\"{artifact_dir}/model.h5\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Iyu1ukRNUEm"
      },
      "outputs": [],
      "source": [
        "# If you don't have these installed\n",
        "#!pip install pydot\n",
        "#!apt-get install graphviz -y\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "# Create a diagram of the model architecture\n",
        "#plot_model(VGG_model, to_file='VGG19model.png', show_shapes=True, show_layer_names=True)\n",
        "plot_model(model, to_file='Resnet50Model.png', show_shapes=True, show_layer_names=True)\n",
        "#plot_model(custom_model, to_file='HALNet_1_Model.png', show_shapes=True, show_layer_names=True)\n",
        "from google.colab import files\n",
        "files.download('VGG19_model.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support\n",
        "import seaborn as sns\n",
        "\n",
        "# Model paths and names\n",
        "models_info = {\n",
        "    \"ResNet50\": \"/content/drive/MyDrive/Colab Notebooks/Final Codes/Resnet50.h5\",\n",
        "    \"VGG19\": \"/content/drive/MyDrive/Colab Notebooks/Final Codes/VGG19.h5\",\n",
        "    \"HALNet1\": \"/content/drive/MyDrive/Colab Notebooks/Final Codes/HALNet1.h5\",\n",
        "    \"HALNet2\": \"/content/drive/MyDrive/Colab Notebooks/Final Codes/HALNet2.h5\",\n",
        "    \"SMVNet\": \"/content/drive/MyDrive/Colab Notebooks/Final Codes/SMVNet.h5\",\n",
        "    \"JAPNet\": \"/content/drive/MyDrive/Colab Notebooks/Final Codes/JAPnet.h5\"\n",
        "}\n",
        "\n",
        "# Function to load model and get predictions\n",
        "def get_model_predictions(model, dataset):\n",
        "    predictions = []\n",
        "    labels = []\n",
        "    for x, y in dataset:\n",
        "        preds = model.predict(x)\n",
        "        predictions.extend(preds.flatten())  # Make sure to flatten or adjust depending on model output\n",
        "        labels.extend(y.numpy())\n",
        "    return np.array(predictions), np.array(labels)\n",
        "\n",
        "# Prepare to collect ROC data\n",
        "roc_data = []\n",
        "\n",
        "# Process each model\n",
        "for model_name, model_path in models_info.items():\n",
        "    # Load the model\n",
        "    model = load_model(model_path)\n",
        "\n",
        "    # Get predictions and labels\n",
        "    predictions, labels = get_model_predictions(model, val_ds)\n",
        "\n",
        "    threshold = 0.5\n",
        "    predicted_labels = (predictions > threshold).astype(int)\n",
        "    # Compute confusion matrix\n",
        "    cm = confusion_matrix(labels, predicted_labels)\n",
        "    # Compute other metrics\n",
        "    precision, recall, f1_score, _ = precision_recall_fscore_support(labels, predicted_labels, average='binary')\n",
        "    # Plot confusion matrix\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
        "    plt.xlabel('Predicted Labels')\n",
        "    plt.ylabel('True Labels')\n",
        "    plt.title(f'Confusion Matrix for {model_name}')\n",
        "    plt.show()\n",
        "\n",
        "    # Print metrics\n",
        "    print(f\"Metrics for {model_name}:\")\n",
        "    print(f\"Precision: {precision:.2f}\")\n",
        "    print(f\"Recall: {recall:.2f}\")\n",
        "    print(f\"F1 Score: {f1_score:.2f}\")\n",
        "    print(\"------\\n\")\n",
        "\n",
        "\n",
        "    # Calculate ROC AUC\n",
        "    fpr, tpr, _ = roc_curve(labels, predictions)\n",
        "    auc = roc_auc_score(labels, predictions)\n",
        "\n",
        "    # Store the ROC data\n",
        "    roc_data.append((fpr, tpr, auc, model_name))\n",
        "\n",
        "# Plot all ROC curves in one figure\n",
        "plt.figure(figsize=(10, 8))\n",
        "for fpr, tpr, auc, model_name in roc_data:\n",
        "    plt.plot(fpr, tpr, label=f'{model_name} (AUC = {auc:.2f})')\n",
        "\n",
        "# Add the random chance line\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "\n",
        "# Customize the plot\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Comparison of ROC Curves Across Models')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "zDe0rxUkKrqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r6-sjZcggFvc"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}