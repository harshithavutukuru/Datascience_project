{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "9NxdmrzJKxMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wWoFQLm2pVOn"
      },
      "outputs": [],
      "source": [
        "!pip install kaggle -Uqq\n",
        "!mkdir /root/.kaggle\n",
        "!mkdir model_checkpoints\n",
        "!cp /content/drive/MyDrive/kaggle.json  /root/.kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WIlXqfQKpege"
      },
      "outputs": [],
      "source": [
        "!pip install wandb -Uqq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9fTRw-cJphCT"
      },
      "outputs": [],
      "source": [
        "!kaggle datasets download -d preetviradiya/brian-tumor-dataset\n",
        "!mkdir data\n",
        "!unzip -d data -q /content/brian-tumor-dataset.zip\n",
        "!rm -rf /content/brian-tumor-dataset.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8sInw8QzplVw"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "from pathlib import Path\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "\n",
        "tf.keras.utils.set_random_seed(42)\n",
        "tf.config.experimental.enable_op_determinism()\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJn5EOotuQ-D"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "import wandb\n",
        "from wandb.integration.keras import WandbCallback\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cPtQPDNep2qX"
      },
      "outputs": [],
      "source": [
        "from dataclasses import dataclass\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class Parameters:\n",
        "    learning_rate: float = 0.001\n",
        "    batch_size: int = 32\n",
        "    data_dir = Path('/content/data/Brain Tumor Data Set/')\n",
        "    train_dir = data_dir / 'Brain Tumor Data Set'\n",
        "    verbose = 1\n",
        "    epochs = 100\n",
        "    img_size = 224\n",
        "    img_shape = (img_size, img_size, 3)\n",
        "    class_names = None\n",
        "    seed = 42\n",
        "\n",
        "config = Parameters()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ejThXeJqrmc"
      },
      "outputs": [],
      "source": [
        "train_loader, val_loader = tf.keras.utils.image_dataset_from_directory(\n",
        "  config.train_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"both\",\n",
        "  seed=42,\n",
        "  image_size=(config.img_size, config.img_size),\n",
        "  batch_size=config.batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kAJ891Hwq_3R"
      },
      "outputs": [],
      "source": [
        "\n",
        "config.class_names = train_loader.class_names\n",
        "config.num_classes = len(config.class_names)\n",
        "print(config.class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FvvW5T3isGA_"
      },
      "outputs": [],
      "source": [
        "def plot_images(dataset, class_names, num_images=25):\n",
        "    # Get a batch of images and labels from the dataset\n",
        "    image_batch, label_batch = next(iter(dataset))\n",
        "\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    sns.set_style(\"whitegrid\")\n",
        "    for i in range(num_images):\n",
        "        ax = plt.subplot(5, 5, i + 1)\n",
        "        plt.imshow(image_batch[i].numpy().astype(\"uint8\"))\n",
        "        label = class_names[label_batch[i]]\n",
        "        plt.title(label)\n",
        "        plt.axis(\"off\")\n",
        "    plt.tight_layout()\n",
        "\n",
        "plot_images(train_loader, class_names=train_loader.class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-FjGmYTrsMJM"
      },
      "outputs": [],
      "source": [
        "def plot_class_distribution(train_ds, test_ds, class_names):\n",
        "    # Get the class distributions in the datasets\n",
        "    train_class_distribution = Counter([class_names[label] for images, labels in train_ds for label in labels])\n",
        "    test_class_distribution = Counter([class_names[label] for images, labels in test_ds for label in labels])\n",
        "\n",
        "    # Sort the keys and values of the class distributions\n",
        "    train_keys, train_values = zip(*sorted(train_class_distribution.items()))\n",
        "    test_keys, test_values = zip(*sorted(test_class_distribution.items()))\n",
        "\n",
        "    # Create a figure with two subplots\n",
        "    fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "    # Plot the class distribution in the training dataset\n",
        "    sns.barplot(x=list(train_keys), y=list(train_values), ax=axs[0], palette=\"Blues_d\")\n",
        "    axs[0].set_title('Class Distribution in Training Dataset')\n",
        "    axs[0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "    # Plot the class distribution in the test dataset\n",
        "    sns.barplot(x=list(test_keys), y=list(test_values), ax=axs[1], palette=\"Greens_d\")\n",
        "    axs[1].set_title('Class Distribution in Test Dataset')\n",
        "    axs[1].tick_params(axis='x', rotation=45)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_class_distribution(train_loader, val_loader, config.class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-6S3gPJNseI0"
      },
      "outputs": [],
      "source": [
        "rescaling = layers.Rescaling(1.0 / 255)\n",
        "resize = layers.Resizing(config.img_size, config.img_size)\n",
        "augmentation_layer = tf.keras.Sequential([\n",
        "    layers.RandomFlip(\"horizontal_and_vertical\", seed=42),\n",
        "    layers.RandomRotation(0.3, seed=42),\n",
        "    layers.RandomZoom(0.3, seed=42),\n",
        "    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vKsgdfxRs9yo"
      },
      "outputs": [],
      "source": [
        "def create_model():\n",
        "    tf.keras.backend.clear_session()\n",
        "    model = tf.keras.Sequential([\n",
        "    resize,\n",
        "    tf.keras.Input(shape=(config.img_size, config.img_size, 3)),\n",
        "    rescaling,\n",
        "    augmentation_layer,\n",
        "    layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Conv2D(128, 3, padding='same', activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Conv2D(256, 3, padding='same', activation='relu'),\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(512, activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.25),\n",
        "    layers.Dense(1,activation='sigmoid')\n",
        "    ])\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xD3_co7WtITL"
      },
      "outputs": [],
      "source": [
        "model = create_model()\n",
        "batch = next(iter(train_loader))\n",
        "outputs = model(batch[0])\n",
        "model.summary(expand_nested=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Whb4o5vtKsW"
      },
      "outputs": [],
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "loss = tf.keras.losses.BinaryCrossentropy()\n",
        "roc_auc = tf.keras.metrics.AUC(curve='ROC', name='roc_auc')\n",
        "accuracy = tf.keras.metrics.BinaryAccuracy(name='accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Iwurq5bt1U5"
      },
      "outputs": [],
      "source": [
        "# define callbacks\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor=\"val_loss\",\n",
        "    factor=0.1,\n",
        "    patience=3,\n",
        "    verbose=1,\n",
        "    mode=\"auto\",\n",
        "    min_delta=0.0001,\n",
        "    cooldown=0,\n",
        "    min_lr=0,\n",
        ")\n",
        "checkpoint_filepath = \"/content/model_checkpoints/models_resnet_50/model_{epoch:02d}_val_roc_auc_{val_roc_auc:.4f}_val_loss_{val_loss:.4f}_val_accuracy_{val_accuracy:.4f}.keras\"\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    monitor=\"val_loss\",\n",
        "    verbose=0,\n",
        "    save_best_only=True,\n",
        "    save_weights_only=True,\n",
        "    mode=\"auto\",\n",
        "    save_freq=\"epoch\",\n",
        ")\n",
        "\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-osx78qjuD3r"
      },
      "outputs": [],
      "source": [
        "train_ds = train_loader.cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "val_ds = val_loader.cache().prefetch(buffer_size=tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kb0ufoBsuA44"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=optimizer, loss=loss, metrics=[roc_auc, accuracy])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# If you don't have these installed\n",
        "!pip install pydot\n",
        "!apt-get install graphviz -y\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "# Create a diagram of the model architecture\n",
        "\n",
        "plot_model(model, to_file='SMVNet_Model.png', show_shapes=True, show_layer_names=True)\n",
        "from google.colab import files\n",
        "files.download('SMVNet_Model.png')"
      ],
      "metadata": {
        "id": "bp8UIi6ORYXa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5a6avu7JuBDy"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "WANDB_API_KEY = userdata.get('wandb_api')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Zh_V_CDuIbv"
      },
      "outputs": [],
      "source": [
        "wandb.login(key=WANDB_API_KEY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UdGNFqBUuMIF"
      },
      "outputs": [],
      "source": [
        "run = wandb.init(project=\"cortex\", entity=\"shivanikotian18\", job_type=\"train\", group='CNN',tags=['CNN_Shivani'], config=config)\n",
        "assert run is wandb.run, \"Something went wrong\"\n",
        "#train and validate the model\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=config.epochs,\n",
        "    callbacks=[checkpoint, WandbCallback(save_weights_only=False),reduce_lr, early_stopping],\n",
        ")\n",
        "run.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PiVfDKzCwSfS"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}